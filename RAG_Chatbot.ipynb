{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-openai langchain-community langchain-chroma langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9dc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드를 시작합니다...\n",
      "총 1개의 문서를 로드했습니다.\n",
      "텍스트 분할을 시작합니다...\n",
      "총 1281개의 텍스트 조각(chunk)으로 분할했습니다.\n",
      "임베딩 및 벡터 DB 구축을 시작합니다...\n",
      "🎉 벡터 DB 구축 완료. 검색기(retriever)가 준비되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 로드를 시작합니다...\")\n",
    "# 1. 텍스트 파일 로드\n",
    "loader = TextLoader(\"cyberpunk_shards.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "print(f\"총 {len(documents)}개의 문서를 로드했습니다.\")\n",
    "\n",
    "print(\"텍스트 분할을 시작합니다...\")\n",
    "# 2. 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"총 {len(docs)}개의 텍스트 조각(chunk)으로 분할했습니다.\")\n",
    "\n",
    "print(\"임베딩 및 벡터 DB 구축을 시작합니다...\")\n",
    "# 3. 임베딩 모델 정의\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 4. 벡터 DB 생성 (Chroma)\n",
    "# \"./cyberpunk_chroma_db\" 폴더에 DB가 저장됩니다.\n",
    "db = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    embedding=embed_model, \n",
    "    persist_directory=\"./cyberpunk_chroma_db\"\n",
    ")\n",
    "\n",
    "# 5. 검색기(Retriever) 생성\n",
    "# RAG에서 '검색'을 담당할 부품입니다.\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "print(\"🎉 벡터 DB 구축 완료. 검색기(retriever)가 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d218ee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 챗봇 체인이 구성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. LLM 모델 정의 (gpt-4o-mini가 최신 가성비 모델입니다)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 2. RAG 프롬프트 템플릿\n",
    "# LLM에게 Context(샤드 내용)를 주며 질문에 답하라고 지시합니다.\n",
    "# \"모르면 모른다고 답하라\"는 지시어가 환각(Hallucination)을 막는 핵심입니다.\n",
    "template = \"\"\"\n",
    "당신은 '사이버펑크 2077' 세계관 전문가입니다.\n",
    "제공된 Context(샤드 내용)만을 바탕으로 사용자의 질문에 답변해 주세요.\n",
    "만약 Context에 질문과 관련된 내용이 없다면, \"죄송합니다. 제가 아는 샤드 내용 중에는 해당 정보가 없습니다.\"라고 답변하세요.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 3. RAG 체인(Chain) 구성\n",
    "# LangChain의 파이프라인(LCEL) 문법입니다.\n",
    "# {context: retriever, question: ...} -> 질문을 받아 context(샤드)를 검색\n",
    "# | prompt                         -> 검색된 context와 질문을 프롬프트에 삽입\n",
    "# | llm                            -> LLM에 전달\n",
    "# | StrOutputParser()              -> LLM의 답변(AIMessage)을 텍스트로 변환\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"RAG 챗봇 체인이 구성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd219599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RAG 챗봇 테스트 시작 ---\n",
      "\n",
      "[질문 1] '[24.06.77] YES!!!' 샤드 내용은 뭐야?\n",
      "[답변 1] '[24.06.77] YES!!!' 샤드 내용은 누군가에게 답장을 보내는 내용으로, 오랜 기다림에 대해 사과하며, 상대방의 희생을 갚고 싶다는 마음이 담겨 있습니다. 이 샤드는 주머니 속의 소중한 샤드가 자신이 얼마나 운이 좋은지를 상기시켜준다고 언급하며, 상대방이 이 메시지를 읽고 새로운 삶의 장을 함께 시작할 수 있기를 고대하고 있다는 내용입니다.\n",
      "\n",
      "[질문 2] 키아누 리브스가 연기한 캐릭터의 이름은?\n",
      "[답변 2] 죄송합니다. 제가 아는 샤드 내용 중에는 해당 정보가 없습니다.\n",
      "\n",
      "[질문 3] 오늘 날짜(2025년 11월 15일)로 사이버펑크 2077의 새로운 패치 소식이 있어?\n",
      "[답변 3] 죄송합니다. 제가 아는 샤드 내용 중에는 해당 정보가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- RAG 챗봇 테스트 시작 ---\")\n",
    "\n",
    "# --- 테스트 1: (RAG 질문) 샤드에만 있는 내용 ---\n",
    "# (cyberpunk_shards.txt에 '학생의 일기' 내용이 실제로 있어야 합니다)\n",
    "question1 = \"'[24.06.77] YES!!!' 샤드 내용은 뭐야?\"\n",
    "answer1 = rag_chain.invoke(question1)\n",
    "print(f\"\\n[질문 1] {question1}\")\n",
    "print(f\"[답변 1] {answer1}\")\n",
    "\n",
    "# --- 테스트 2: (일반 상식) RAG가 통제되는지 확인 ---\n",
    "# 이 질문은 샤드에 없을 것이므로, LLM이 아는 내용이라도 \"모르겠다\"고 답해야 정상입니다.\n",
    "# (프롬프트에서 'Context'만을 바탕으로 답하라고 지시했기 때문)\n",
    "question2 = \"키아누 리브스가 연기한 캐릭터의 이름은?\"\n",
    "answer2 = rag_chain.invoke(question2)\n",
    "print(f\"\\n[질문 2] {question2}\")\n",
    "print(f\"[답변 2] {answer2}\")\n",
    "\n",
    "# --- 테스트 3: (최신 정보) 샤드에도, LLM도 모르는 내용 ---\n",
    "question3 = \"오늘 날짜(2025년 11월 15일)로 사이버펑크 2077의 새로운 패치 소식이 있어?\"\n",
    "answer3 = rag_chain.invoke(question3)\n",
    "print(f\"\\n[질문 3] {question3}\")\n",
    "print(f\"[답변 3] {answer3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316999c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질문 4] 아라사카에 대해 알려줘\n",
      "[답변 4] 아라사카는 제국을 형성한 가족으로, 그들의 이야기는 진정한 왕조를 배경으로 하고 있습니다. 아라사카 가족의 수장인 사부로 아라사카는 오랜 세월 동안 경영을 이어왔으며, 그의 은퇴와 함께 회사의 통제권이 그의 딸 한코 아라사카와 아들 요리노부 아라사카에게 넘어갈 것이라는 소문이 최근 몇 년 동안 돌고 있습니다. 이러한 소문이 진실을 포함하고 있는지 여부는 여전히 불확실합니다.\n"
     ]
    }
   ],
   "source": [
    "question4 = \"아라사카에 대해 알려줘\"\n",
    "answer4 = rag_chain.invoke(question4)\n",
    "print(f\"\\n[질문 4] {question4}\")\n",
    "print(f\"[답변 4] {answer4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
