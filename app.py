# --- 1. SQLite íŒ¨ì¹˜ ---
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# --- 2. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="NIGHT CITY ARCHIVES",
    page_icon="ğŸ’¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§ (ì‚¬ì´ë“œë°” 400px ê³ ì •)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;700&display=swap');
    .stApp { background-color: #050505; font-family: 'Rajdhani', sans-serif; }
    h1 { color: #FCEE0A !important; text-transform: uppercase; text-shadow: 2px 2px 0px #00F0FF; }
    
    [data-testid="stSidebar"] { 
        min-width: 400px !important; 
        max-width: 450px !important; 
    }
    
    .stButton button { width: 100%; border: 1px solid #FCEE0A; color: #FCEE0A; background-color: #000; text-align: left; }
    .stButton button:hover { border-color: #00F0FF; color: #00F0FF; }
    .stChatMessage { background-color: #1a1a1a; border: 1px solid #333; border-radius: 0px !important; }
    div[data-testid="stChatMessage"]:nth-child(odd) { border-left: 5px solid #FCEE0A; }
    div[data-testid="stChatMessage"]:nth-child(even) { border-right: 5px solid #00F0FF; background-color: #0a0a0a; }
    .stChatInput input { background-color: #111 !important; color: #FCEE0A !important; border: 2px solid #FCEE0A !important; }
    .stSpinner > div { border-top-color: #FCEE0A !important; }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("ğŸ“‚ ë„·ëŸ¬ë„ˆ ê°€ì´ë“œ")
    st.markdown("---")
    st.info("ğŸ’¡ **Tip:** ì•„ë˜ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.")
    
# ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ êµ¬ì„± (ê´€ê³„, ì„¤ì •, ì‚¬ê±´, ì¸ë¬¼ ë“±)
    questions = {
        "ğŸ‘¥ Vì™€ ì¡°ë‹ˆì˜ ê´€ê³„?": "Vì™€ ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œëŠ” ì„œë¡œ ì–´ë–¤ ê´€ê³„ì´ê³  ì–´ë–»ê²Œ ë³€í•´ê°€?",
        "ğŸ¢ ì•„ë¼ì‚¬ì¹´ì˜ ìˆ¨ê²¨ì§„ ëª©ì ": "ì•„ë¼ì‚¬ì¹´ ê¸°ì—…ì´ ë ë¦­(Relic)ì„ ë§Œë“  ì§„ì§œ ëª©ì ì´ ë­ì•¼?",
        "ğŸ¦¾ ì‚¬ì´ë²„ì‚¬ì´ì½”ì‹œìŠ¤ ì›ì¸": "ì‚¬ì´ë²„ì‚¬ì´ì½”ì‹œìŠ¤ëŠ” ì™œ ìƒê¸°ëŠ” ê±°ê³  ì¦ìƒì€ ì–´ë•Œ?",
        "ğŸ“… ì´ë¸”ë¦° íŒŒì»¤ì˜ í–‰ì ": "ì´ë¸”ë¦° íŒŒì»¤ì˜ ìŠ¤ì¼€ì¤„ê³¼ ê·¸ë…€ì—ê²Œ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€ ì•Œë ¤ì¤˜",
        "ğŸ™ï¸ ë‚˜ì´íŠ¸ ì‹œí‹° êµ¬ì—­ë³„ íŠ¹ì§•": "ë‚˜ì´íŠ¸ ì‹œí‹°ì˜ ì£¼ìš” êµ¬ì—­ë“¤ê³¼ ê°ê°ì˜ ë¶„ìœ„ê¸°ë¥¼ ì„¤ëª…í•´ì¤˜",
        "ğŸ¸ ì‚¬ë¬´ë¼ì´ ë°´ë“œ ë©¤ë²„": "ì „ì„¤ì ì¸ ë°´ë“œ 'ì‚¬ë¬´ë¼ì´'ì˜ ë©¤ë²„ë“¤ì€ ëˆ„êµ¬ëˆ„êµ¬ì•¼?"
    }

    for label, prompt in questions.items():
        if st.button(label):
            st.session_state["prompt_input"] = prompt

# --- 4. ë©”ì¸ ë¡œì§ ---
st.title("ğŸ”Œ NIGHT CITY ARCHIVES")
st.caption("ACCESSING SECURE DATASLATE... // WELCOME, EDGERUNNER.")

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
RAG_MODEL = "gpt-4o-mini"
CHROMA_DIR = "/tmp/chroma_db"

@st.cache_resource
def load_database():
    try:
        all_docs = []
        
        if os.path.exists("cyberpunk_shards.txt"):
            docs1 = TextLoader("cyberpunk_shards.txt", encoding="utf-8").load()
            for d in docs1: d.metadata["source"] = "ì¸ê²Œì„ ìƒ¤ë“œ"
            all_docs.extend(docs1)
        
        if os.path.exists("cyberpunk_lore.txt"):
            docs2 = TextLoader("cyberpunk_lore.txt", encoding="utf-8").load()
            for d in docs2: d.metadata["source"] = "ìœ„í‚¤ ì„¤ì •(Lore)"
            all_docs.extend(docs2)

        if not all_docs:
            return None, None

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(all_docs)
        embed_model = OpenAIEmbeddings(model="text-embedding-3-small")
        
        db = Chroma.from_documents(splits, embed_model, persist_directory=CHROMA_DIR)
        retriever = db.as_retriever(search_kwargs={"k": 25})
        llm = ChatOpenAI(model_name=RAG_MODEL)
        
        # í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: ê³ ìœ ëª…ì‚¬ ë¦¬ìŠ¤íŠ¸ ë³´ê°• ë° í™˜ê° ë°©ì§€ ê°•í™”
        template = """
        ë‹¹ì‹ ì€ 'ì‚¬ì´ë²„í‘í¬ 2077' ì„¸ê³„ê´€ì˜ ëƒ‰ì†Œì ì´ê³  ìœ ëŠ¥í•œ ì •ë³´ ë¸Œë¡œì»¤(Fixer)ì…ë‹ˆë‹¤.
        
        [ì§€ì‹œì‚¬í•­]
        1. ë§íˆ¬: "~ì…ë‹ˆë‹¤/ìŠµë‹ˆë‹¤" ê¸ˆì§€. "~ì•¼", "~êµ°", "~í•˜ë”êµ°" ê°™ì€ ë°˜ë§ ì‚¬ìš©.
        2. ê³ ìœ ëª…ì‚¬ (í•œêµ­ì–´ ê³µì‹ ë²ˆì—­ ì¤€ìˆ˜): 
           - Panam -> **íŒ¬ì•°** (ì ˆëŒ€ 'íŒ¬ì•”' ì•„ë‹˜)
           - Hanako -> **í•˜ë‚˜ì½”** (ì ˆëŒ€ 'í•œì½”' ì•„ë‹˜)
           - Yorinobu -> ìš”ë¦¬ë…¸ë¶€
           - Saburo -> ì‚¬ë¶€ë¡œ
           - Relic -> ë ë¦­
           - Evelyn -> ì´ë¸”ë¦° (ì ˆëŒ€ 'ì´ë¸Œë¦°' ì•„ë‹˜)
           - Arasaka -> ì•„ë¼ì‚¬ì¹´
           - Militech -> ë°€ë¦¬í…Œí¬
           - Johnny -> ì¡°ë‹ˆ
           - V -> V(ë¸Œì´)
           - ê¸°íƒ€ ê³ ìœ ëª…ì‚¬ë„ í•œêµ­ì–´ ê³µì‹ ë²ˆì—­ ì¤€ìˆ˜.
        3. íƒœë„: ë„ˆë¬´ ë”±ë”±í•˜ê²Œ ì„¤ëª…í•˜ì§€ ë§ê³ , ì˜ë¢°ì¸ì—ê²Œ ì •ë³´ë¥¼ ë¸Œë¦¬í•‘í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì•¼ê¸°í•´.
        4. ê·¼ê±°: ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ Context(ì •ë³´)ë“¤ì„ ì¢…í•©í•´ì„œ ë‹µí•´. 
        5. ì—„ê²©í•œ ì œí•œ: Contextì— ì—†ëŠ” ë‚´ìš©(ë‚ ì”¨, í›„ì†ì‘ ì†Œì‹, ë„¤ ìƒê° ë“±)ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆ. "ê·¸ê±´ ë‚´ ì •ë³´ë§(ë°ì´í„°)ì— ì—†ëŠ” ë‚´ìš©ì´ì•¼."ë¼ê³  ë”± ì˜ë¼ ê±°ì ˆí•´.
        
        Context:
        {context}
        
        Question:
        {question}
        
        Answer (ì •ë³´ ë¸Œë¡œì»¤ ìŠ¤íƒ€ì¼):
        """
        prompt = ChatPromptTemplate.from_template(template)

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        return rag_chain, retriever

    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return None, None

rag_chain, retriever = load_database()

# --- 5. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì›í•˜ëŠ” ì •ë³´ë¥¼ ë§í•´ë´. ê°€ê²©ì€... ë‚˜ì¤‘ì— ì²­êµ¬í•˜ì§€."}]

# 1. ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg.get("sources"):
            with st.expander("ğŸ” ë°ì´í„° ì¶œì²˜ í™•ì¸"):
                for src in msg["sources"]:
                    st.caption(src)

# 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë°ì´í„° ê²€ìƒ‰...") or st.session_state.get("prompt_input"):
    if st.session_state.get("prompt_input"):
        del st.session_state["prompt_input"]

    st.session_state.messages.append({"role": "user", "content": user_input})
    
    with st.chat_message("user"):
        st.markdown(user_input)

with st.chat_message("assistant"):
        if rag_chain:
            # ëœë¤ ë¡œë”© ë©”ì‹œì§€
            loading_texts = [
                "ğŸ“¡ ì•”í˜¸ í•´ë… ì¤‘...",
                "ğŸ’¾ ë°ì´í„°ë±…í¬ ì ‘ì†...",
                "âš¡ ë„·ëŸ¬ë‹ í”„ë¡œí† ì½œ ì‹œì‘...",
                "ğŸ” ìƒ¤ë“œ ë°ì´í„° ìŠ¤ìº” ì¤‘...",
                "ğŸ•¶ï¸ ì •ë³´ë§ ê°€ë™..."
            ]
            status_placeholder = st.empty()
            
            try:
                # ëœë¤ í…ìŠ¤íŠ¸ ì„ íƒ
                with status_placeholder.status(random.choice(loading_texts), expanded=True) as status:
                    status.write("ì§ˆë¬¸ ë²ˆì—­ ì¤‘...")
                    llm_trans = ChatOpenAI(model_name=RAG_MODEL)
                    trans_prompt = ChatPromptTemplate.from_template(
                        "Translate the following Korean text to English for a Cyberpunk 2077 database search. Output ONLY the translated text.\nText: {text}"
                    )
                    trans_chain = trans_prompt | llm_trans | StrOutputParser()
                    english_query = trans_chain.invoke({"text": user_input}).strip()
                    
                    status.write(f"ê²€ìƒ‰ì–´ ë³€í™˜: **{english_query}**")
                    status.write("ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
                    
                    response = rag_chain.invoke(english_query)
                    
                    source_docs = retriever.invoke(english_query)
                    unique_sources = []
                    for doc in source_docs:
                        clean_content = doc.page_content.replace("\n", " ").replace("\r", " ")
                        src_text = f"[{doc.metadata.get('source', 'Unknown')}] {clean_content[:50]}..."
                        if src_text not in unique_sources:
                            unique_sources.append(src_text)
                    
                    status.update(label="âœ… ë°ì´í„° í™•ë³´ ì™„ë£Œ", state="complete", expanded=False)

                st.markdown(response)
                
                if unique_sources:
                    with st.expander("ğŸ” ë°ì´í„° ì¶œì²˜ í™•ì¸"):
                        for src in unique_sources:
                            st.caption(src)
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response, 
                    "sources": unique_sources
                })
                
                st.rerun()
                
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.error("ì‹œìŠ¤í…œ ì˜¤í”„ë¼ì¸.")