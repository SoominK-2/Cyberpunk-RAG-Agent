import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="NIGHT CITY ARCHIVES",
    page_icon="ğŸ’¾",
    layout="wide",
    initial_sidebar_state="expanded" # ì‚¬ì´ë“œë°” ê¸°ë³¸ ì—´ë¦¼
)

# --- 2. ì‚¬ì´ë“œë°” (ì‚¬ìš©ì ê°€ì´ë“œ & ì¶”ì²œ ì§ˆë¬¸) ---
with st.sidebar:
    st.title("ë„·ëŸ¬ë„ˆ ê°€ì´ë“œ")
    st.markdown("---")
    
    st.subheader("ì´ìš© íŒ")
    st.info(
        """
        ì´ ì—ì´ì „íŠ¸ëŠ” **ê²Œì„ ë‚´ ìƒ¤ë“œ(Shard)**ì™€ **ìœ„í‚¤ ë°ì´í„°**ë¥¼ 
        ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
        
        - **ê°€ëŠ¥:** íŠ¹ì • ì¸ë¬¼, ì‚¬ê±´, ìƒ¤ë“œ ë‚´ìš© ìš”ì•½
        - **ë¶ˆê°€ëŠ¥:** ì‹¤ì‹œê°„ ë‰´ìŠ¤, ê²Œì„ ê³µëµ, ê°œì¸ì ì¸ ì¡ë‹´
        """
    )
    
    st.subheader("ì¶”ì²œ ì§ˆë¬¸")
    example_questions = [
        "ì•„ë¼ì‚¬ì¹´ì™€ Vì˜ ê´€ê³„ì— ëŒ€í•´ ë§í•´ì¤˜",
        "ì‚¬ì´ë²„ì‚¬ì´ì½”ì‹œìŠ¤ë€ ë­ì•¼?",
        "ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œëŠ” ëˆ„êµ¬ì•¼?",
        "'í•™ìƒì˜ ì¼ê¸°' ìƒ¤ë“œ ë‚´ìš©ì€?",
        "ë‚˜ì´íŠ¸ ì‹œí‹°ì˜ ì£¼ìš” ê¸°ì—…ë“¤ì€?"
    ]
    
    for ex in example_questions:
        if st.button(ex):
            # ë²„íŠ¼ í´ë¦­ ì‹œ ì…ë ¥ì°½ì— ìë™ ì…ë ¥ íš¨ê³¼ (session_state í™œìš©)
            st.session_state.prompt_input = ex

# --- 3. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ---
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
RAG_MODEL = "gpt-4o-mini"
CHROMA_DIR = "./cyberpunk_chroma_db"

# ì»¤ìŠ¤í…€ CSS (ì´ì „ê³¼ ë™ì¼)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;700&display=swap');
    .stApp { background-color: #050505; font-family: 'Rajdhani', sans-serif; }
    h1 { color: #FCEE0A !important; text-transform: uppercase; text-shadow: 2px 2px 0px #00F0FF; }
    .stCaption { color: #00F0FF !important; border-left: 3px solid #FCEE0A; padding-left: 10px; }
    .stChatMessage { background-color: #1a1a1a; border: 1px solid #333; border-radius: 0px !important; }
    div[data-testid="stChatMessage"]:nth-child(odd) { border-left: 5px solid #FCEE0A; }
    div[data-testid="stChatMessage"]:nth-child(even) { border-right: 5px solid #00F0FF; background-color: #0a0a0a; }
    .stChatInput input { background-color: #111 !important; color: #FCEE0A !important; border: 2px solid #FCEE0A !important; }
    .stSpinner > div { border-top-color: #FCEE0A !important; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ”Œ NIGHT CITY ARCHIVES")
st.caption("ACCESSING SECURE DATASLATE... // WELCOME, EDGERUNNER.")

# --- 4. ë°ì´í„° ë¡œë“œ ë° ì²´ì¸ êµ¬ì¶• (ì¶œì²˜ ê¸°ëŠ¥ ì¶”ê°€) ---
@st.cache_resource
def load_database():
    try:
        all_docs = []
        
        # (1) ìƒ¤ë“œ ë°ì´í„° ë¡œë“œ
        if os.path.exists("cyberpunk_shards.txt"):
            loader1 = TextLoader("cyberpunk_shards.txt", encoding="utf-8")
            docs1 = loader1.load()
            for d in docs1: d.metadata["source"] = "ì¸ê²Œì„ ìƒ¤ë“œ ë°ì´í„°"
            all_docs.extend(docs1)

        # (2) ìœ„í‚¤(Lore) ë°ì´í„° ë¡œë“œ
        if os.path.exists("cyberpunk_lore.txt"):
            loader2 = TextLoader("cyberpunk_lore.txt", encoding="utf-8")
            docs2 = loader2.load()
            for d in docs2: d.metadata["source"] = "ìœ„í‚¤(Lore) ë°ì´í„°"
            all_docs.extend(docs2)
            
        if not all_docs:
            return None

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(all_docs)

        embed_model = OpenAIEmbeddings(model="text-embedding-3-small")
        db = Chroma.from_documents(splits, embed_model, persist_directory=CHROMA_DIR)
        retriever = db.as_retriever()
        
        llm = ChatOpenAI(model_name=RAG_MODEL)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = (
            "ë‹¹ì‹ ì€ 'ì‚¬ì´ë²„í‘í¬ 2077' ì„¸ê³„ê´€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
            "ì•„ë˜ ì œê³µëœ Contextë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. "
            "ë§Œì•½ Contextì— ì •ë³´ê°€ ì—†ë‹¤ë©´ 'í•´ë‹¹ ë‚´ìš©ì€ ë‚´ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ì„¸ìš”. "
            "\n\n"
            "Context:\n{context}"
        )
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
        ])

        # ì¶œì²˜ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ì²´ì¸ ìƒì„± (create_retrieval_chain ì‚¬ìš©)
        question_answer_chain = create_stuff_documents_chain(llm, prompt)
        rag_chain = create_retrieval_chain(retriever, question_answer_chain)
        
        return rag_chain

    except Exception as e:
        st.error(f"âš ï¸ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return None

rag_chain = load_database()

# --- 5. ì±„íŒ… UI ë° ë¡œì§ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "ì›í•˜ëŠ” ì •ë³´ë¥¼ ë§í•´ë´. ê°€ê²©ì€... ë‚˜ì¤‘ì— ì²­êµ¬í•˜ì§€."})

# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # ì €ì¥ëœ ì¶œì²˜ê°€ ìˆë‹¤ë©´ í‘œì‹œ
        if "sources" in message:
            with st.expander("ğŸ” ì°¸ê³ í•œ ë°ì´í„° ì¶œì²˜"):
                for src in message["sources"]:
                    st.text(f"- {src}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# ì‚¬ì´ë“œë°” ë²„íŠ¼ì„ ëˆŒë €ë‹¤ë©´ ê·¸ ê°’ì„, ì•„ë‹ˆë©´ ì¼ë°˜ ì…ë ¥ì„ ë°›ìŒ
if user_input := st.chat_input("ë°ì´í„° ê²€ìƒ‰...") or st.session_state.get("prompt_input"):
    # ë²„íŠ¼ í´ë¦­ê°’ ì´ˆê¸°í™” (ì¬ì‹¤í–‰ ë°©ì§€)
    if st.session_state.get("prompt_input"):
        del st.session_state["prompt_input"]

    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ“¡ CONNECTING TO NET..."):
            if rag_chain:
                # ì²´ì¸ ì‹¤í–‰ (ì…ë ¥ í‚¤ëŠ” 'input'ì´ì–´ì•¼ í•¨)
                result = rag_chain.invoke({"input": user_input})
                
                response_text = result["answer"]
                source_docs = result["context"]
                
                # ì¶œì²˜ ì •ë¦¬ (ì¤‘ë³µ ì œê±°)
                sources = []
                for doc in source_docs:
                    # ë©”íƒ€ë°ì´í„°ë‚˜ ë‚´ìš©ì˜ ì¼ë¶€ë¥¼ ì¶œì²˜ë¡œ í‘œì‹œ
                    src_info = f"[{doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}] {doc.page_content[:30]}..."
                    if src_info not in sources:
                        sources.append(src_info)

                st.markdown(response_text)
                
                # ì¶œì²˜ ì•„ì½”ë””ì–¸ í‘œì‹œ
                if sources:
                    with st.expander("ğŸ” ì°¸ê³ í•œ ë°ì´í„° ì¶œì²˜"):
                        for src in sources:
                            st.text(f"- {src}")
                
                # ì„¸ì…˜ì— ë‹µë³€ê³¼ ì¶œì²˜ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response_text,
                    "sources": sources
                })
            else:
                st.error("ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨")