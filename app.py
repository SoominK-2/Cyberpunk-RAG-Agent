# --- 1. SQLite íŒ¨ì¹˜ (Streamlit Cloud ì˜¤ë¥˜ ë°©ì§€) ---
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# --- 2. í˜ì´ì§€ ì„¤ì • & ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ ìˆ˜ì • ---
st.set_page_config(
    page_title="NIGHT CITY ARCHIVES",
    page_icon="ğŸ’¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS (ì‚¬ì´ë²„í‘í¬ í…Œë§ˆ + ì‚¬ì´ë“œë°” ë„ˆë¹„ ì¡°ì •)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;700&display=swap');
    .stApp { background-color: #050505; font-family: 'Rajdhani', sans-serif; }
    
    /* í—¤ë” ìŠ¤íƒ€ì¼ */
    h1 { color: #FCEE0A !important; text-transform: uppercase; text-shadow: 2px 2px 0px #00F0FF; }
    
    /* ì‚¬ì´ë“œë°” ë„ˆë¹„ í™•ì¥ (ì¤„ë°”ê¿ˆ ë°©ì§€) */
    [data-testid="stSidebar"] {
        min-width: 400px !important;
        max-width: 500px !important;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton button {
        width: 100%;
        border: 1px solid #FCEE0A;
        color: #FCEE0A;
        background-color: #000;
        text-align: left;
    }
    .stButton button:hover {
        border-color: #00F0FF;
        color: #00F0FF;
    }

    /* ë©”ì‹œì§€ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .stChatMessage { background-color: #1a1a1a; border: 1px solid #333; border-radius: 0px !important; }
    div[data-testid="stChatMessage"]:nth-child(odd) { border-left: 5px solid #FCEE0A; }
    div[data-testid="stChatMessage"]:nth-child(even) { border-right: 5px solid #00F0FF; background-color: #0a0a0a; }
    .stChatInput input { background-color: #111 !important; color: #FCEE0A !important; border: 2px solid #FCEE0A !important; }
    .stSpinner > div { border-top-color: #FCEE0A !important; }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” (ì¶”ì²œ ì§ˆë¬¸) ---
with st.sidebar:
    st.title("ğŸ“‚ ë„·ëŸ¬ë„ˆ ê°€ì´ë“œ")
    st.markdown("---")
    st.info("ğŸ’¡ **Tip:** ì•„ë˜ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.")
    
    # ì§ˆë¬¸ ëª©ë¡ (ì§§ê³  ê°„ê²°í•˜ê²Œ ìˆ˜ì •í•˜ì—¬ ì¤„ë°”ê¿ˆ ìµœì†Œí™”)
    questions = {
        "Vì™€ ì•„ë¼ì‚¬ì¹´ì˜ ê´€ê³„?": "ì•„ë¼ì‚¬ì¹´ì™€ Vì˜ ê´€ê³„ì— ëŒ€í•´ ìƒì„¸íˆ ë§í•´ì¤˜",
        "ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œëŠ” ëˆ„êµ¬?": "ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œì˜ ê³¼ê±°ì™€ ì •ì²´ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
        "ì‚¬ì´ë²„ì‚¬ì´ì½”ì‹œìŠ¤ë€?": "ì‚¬ì´ë²„ì‚¬ì´ì½”ì‹œìŠ¤ì˜ ì›ì¸ê³¼ ì¦ìƒì€ ë­ì•¼?",
        "ë‚˜ì´íŠ¸ ì‹œí‹° ì£¼ìš” êµ¬ì—­": "ë‚˜ì´íŠ¸ ì‹œí‹°ì˜ ì£¼ìš” êµ¬ì—­ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•´ì¤˜",
        "ë ë¦­(Relic)ì´ë€?": "ë ë¦­(Relic)ì´ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤˜"
    }
    
    for label, prompt in questions.items():
        if st.button(label):
            st.session_state["prompt_input"] = prompt

# --- 4. ë©”ì¸ ë¡œì§ ---
st.title("ğŸ”Œ NIGHT CITY ARCHIVES")
st.caption("ACCESSING SECURE DATASLATE... // WELCOME, EDGERUNNER.")

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
RAG_MODEL = "gpt-4o-mini"
CHROMA_DIR = "./cyberpunk_chroma_db"

@st.cache_resource
def load_database():
    try:
        all_docs = []
        files_loaded = []

        # 1. ìƒ¤ë“œ ë°ì´í„° ë¡œë“œ
        if os.path.exists("cyberpunk_shards.txt"):
            loader1 = TextLoader("cyberpunk_shards.txt", encoding="utf-8")
            docs1 = loader1.load()
            for d in docs1: d.metadata["source"] = "ì¸ê²Œì„ ìƒ¤ë“œ"
            all_docs.extend(docs1)
            files_loaded.append("Shards")
        
        # 2. Lore ë°ì´í„° ë¡œë“œ (íŒŒì¼ì´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤)
        if os.path.exists("cyberpunk_lore.txt"):
            loader2 = TextLoader("cyberpunk_lore.txt", encoding="utf-8")
            docs2 = loader2.load()
            for d in docs2: d.metadata["source"] = "ìœ„í‚¤ ì„¤ì •(Lore)"
            all_docs.extend(docs2)
            files_loaded.append("Lore")

        if not all_docs:
            st.error("âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (cyberpunk_shards.txt í™•ì¸ í•„ìš”)")
            return None

        # ë°ì´í„° ë¡œë“œ ì„±ê³µ ë©”ì‹œì§€ (ë””ë²„ê¹…ìš©, ë‚˜ì¤‘ì— ì£¼ì„ ì²˜ë¦¬ ê°€ëŠ¥)
        st.success(f"âœ… ì‹œìŠ¤í…œ ê°€ë™: {', '.join(files_loaded)} ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(all_docs)}ê°œ ë¬¸ì„œ)")

        # 3. í…ìŠ¤íŠ¸ ë¶„í•  ë° ì„ë² ë”©
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(all_docs)
        embed_model = OpenAIEmbeddings(model="text-embedding-3-small")
        
        # 4. DB ìƒì„±
        db = Chroma.from_documents(splits, embed_model, persist_directory=CHROMA_DIR)
        retriever = db.as_retriever()
        
        # 5. LLM & Chain
        llm = ChatOpenAI(model_name=RAG_MODEL)
        
        # ìˆ˜ë™ ì²´ì¸ êµ¬ì„± (LCEL)
        template = """
        ë‹¹ì‹ ì€ 'ì‚¬ì´ë²„í‘í¬ 2077' ì„¸ê³„ê´€ì˜ ì •í†µí•œ ì •ë³´ ë¸Œë¡œì»¤ì…ë‹ˆë‹¤.
        ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ Context(ì •ë³´)ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        
        Context:
        {context}
        
        Question:
        {question}
        
        Answer (í•œê¸€ë¡œ, ì¶œì²˜ê°€ ìˆë‹¤ë©´ ì–¸ê¸‰í•˜ë©°):
        """
        prompt = ChatPromptTemplate.from_template(template)

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        # *ì¤‘ìš”* retriever ê°ì²´ë„ ê°™ì´ ë°˜í™˜í•´ì„œ ë‚˜ì¤‘ì— ì¶œì²˜ ê²€ìƒ‰ì— ì”€
        return rag_chain, retriever

    except Exception as e:
        st.error(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜:\n{e}")
        return None, None

# ë¡œë“œ ì‹¤í–‰
rag_chain, retriever = load_database()

# --- 5. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
# --- 5. ì±„íŒ… UI ë° ë¡œì§ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "ì›í•˜ëŠ” ì •ë³´ë¥¼ ë§í•´ë´. ê°€ê²©ì€... ë‚˜ì¤‘ì— ì²­êµ¬í•˜ì§€."})

# ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message:
            with st.expander("ğŸ” ì°¸ê³ í•œ ë°ì´í„° ì¶œì²˜"):
                for src in message["sources"]:
                    st.text(f"- {src}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë°ì´í„° ê²€ìƒ‰...") or st.session_state.get("prompt_input"):
    if st.session_state.get("prompt_input"):
        del st.session_state["prompt_input"]

    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ“¡ TRANSLATING & SEARCHING..."):
            if rag_chain:
                try:
                    # [í•µì‹¬ ìˆ˜ì • 1] ì§ˆë¬¸ ë²ˆì—­ê¸° (í•œê¸€ -> ì˜ì–´)
                    # DBê°€ ì˜ì–´ë¡œ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ê²€ìƒ‰ ì •í™•ë„ë¥¼ ìœ„í•´ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
                    llm_for_trans = ChatOpenAI(model_name=RAG_MODEL)
                    trans_prompt = ChatPromptTemplate.from_template(
                        "Translate the following Korean text to English for a database search query about Cyberpunk 2077. Just output the translated text:\n\n{korean_text}"
                    )
                    trans_chain = trans_prompt | llm_for_trans | StrOutputParser()
                    
                    # ì‚¬ìš©ìì˜ í•œê¸€ ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­
                    search_query = trans_chain.invoke({"korean_text": user_input})
                    # st.caption(f"Debug: ê²€ìƒ‰ì–´ ë³€í™˜ë¨ -> {search_query}") # ë””ë²„ê¹…ìš© (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)

                    # [í•µì‹¬ ìˆ˜ì • 2] ë²ˆì—­ëœ ì˜ì–´ ì§ˆë¬¸(search_query)ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰
                    # í•˜ì§€ë§Œ ë‹µë³€ ìƒì„±ìš© ì…ë ¥(input)ì€ ì‚¬ìš©ì ì›ë˜ ì§ˆë¬¸(user_input)ì„ ë§¥ë½ìœ¼ë¡œ ì¤„ ìˆ˜ë„ ìˆìœ¼ë‚˜, 
                    # ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ëœ ì˜ì–´ Contextë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œê¸€ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
                    
                    # rag_chainì€ 'input'ì„ ë°›ì•„ì„œ retrievalì„ ìˆ˜í–‰í•˜ë¯€ë¡œ, ì—¬ê¸°ì— ì˜ì–´ ì§ˆë¬¸ì„ ë„£ìŠµë‹ˆë‹¤.
                    result = rag_chain.invoke({"input": search_query})
                    
                    response_text = result["answer"]
                    source_docs = result["context"]
                    
                    # ì¶œì²˜ ì •ë¦¬
                    sources = []
                    for doc in source_docs:
                        src_info = f"[{doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}] {doc.page_content[:30]}..."
                        if src_info not in sources:
                            sources.append(src_info)

                    st.markdown(response_text)
                    
                    if sources:
                        with st.expander("ğŸ” ì°¸ê³ í•œ ë°ì´í„° ì¶œì²˜"):
                            for src in sources:
                                st.text(f"- {src}")
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response_text,
                        "sources": sources
                    })
                except Exception as e:
                     st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
            else:
                st.error("ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨")