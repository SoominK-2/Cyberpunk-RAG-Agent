# --- 1. SQLite íŒ¨ì¹˜ ---
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# --- 2. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="NIGHT CITY ARCHIVES",
    page_icon="ğŸ’¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§ (ì‚¬ì´ë“œë°” 400px ê³ ì •)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;700&display=swap');
    .stApp { background-color: #050505; font-family: 'Rajdhani', sans-serif; }
    h1 { color: #FCEE0A !important; text-transform: uppercase; text-shadow: 2px 2px 0px #00F0FF; }
    
    [data-testid="stSidebar"] { 
        min-width: 400px !important; 
        max-width: 450px !important; 
    }
    
    .stButton button { width: 100%; border: 1px solid #FCEE0A; color: #FCEE0A; background-color: #000; text-align: left; }
    .stButton button:hover { border-color: #00F0FF; color: #00F0FF; }
    .stChatMessage { background-color: #1a1a1a; border: 1px solid #333; border-radius: 0px !important; }
    div[data-testid="stChatMessage"]:nth-child(odd) { border-left: 5px solid #FCEE0A; }
    div[data-testid="stChatMessage"]:nth-child(even) { border-right: 5px solid #00F0FF; background-color: #0a0a0a; }
    .stChatInput input { background-color: #111 !important; color: #FCEE0A !important; border: 2px solid #FCEE0A !important; }
    .stSpinner > div { border-top-color: #FCEE0A !important; }
</style>
""", unsafe_allow_html=True)

# --- 3. ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("ğŸ“‚ ë„·ëŸ¬ë„ˆ ê°€ì´ë“œ")
    st.markdown("---")
    st.info("ğŸ’¡ **Tip:** ì•„ë˜ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.")
    
    questions = {
        "Vì™€ ì•„ë¼ì‚¬ì¹´ì˜ ê´€ê³„?": "ì•„ë¼ì‚¬ì¹´ì™€ Vì˜ ê´€ê³„ì— ëŒ€í•´ ìƒì„¸íˆ ë§í•´ì¤˜",
        "ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œëŠ” ëˆ„êµ¬?": "ì¡°ë‹ˆ ì‹¤ë²„í•¸ë“œì˜ ê³¼ê±°ì™€ ì •ì²´ì— ëŒ€í•´ ì•Œë ¤ì¤˜",
        "ì´ë¸”ë¦° íŒŒì»¤ì˜ ì¼ì •": "ì´ë¸”ë¦° íŒŒì»¤ì˜ ìŠ¤ì¼€ì¤„ ìƒ¤ë“œ ë‚´ìš©ì€ ë­ì•¼?",
        "ë‚˜ì´íŠ¸ ì‹œí‹° ì£¼ìš” êµ¬ì—­": "ë‚˜ì´íŠ¸ ì‹œí‹°ì˜ ì£¼ìš” êµ¬ì—­ê³¼ íŠ¹ì§•ì„ ì„¤ëª…í•´ì¤˜",
        "ë ë¦­(Relic)ì´ë€?": "ë ë¦­(Relic)ì´ ë¬´ì—‡ì´ê³  ì™œ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤˜"
    }
    
    for label, prompt in questions.items():
        if st.button(label):
            st.session_state["prompt_input"] = prompt

# --- 4. ë©”ì¸ ë¡œì§ ---
st.title("ğŸ”Œ NIGHT CITY ARCHIVES")
st.caption("ACCESSING SECURE DATASLATE... // WELCOME, EDGERUNNER.")

os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
RAG_MODEL = "gpt-4o-mini"
CHROMA_DIR = "/tmp/chroma_db"

@st.cache_resource
def load_database():
    try:
        all_docs = []
        
        if os.path.exists("cyberpunk_shards.txt"):
            docs1 = TextLoader("cyberpunk_shards.txt", encoding="utf-8").load()
            for d in docs1: d.metadata["source"] = "ì¸ê²Œì„ ìƒ¤ë“œ"
            all_docs.extend(docs1)
        
        if os.path.exists("cyberpunk_lore.txt"):
            docs2 = TextLoader("cyberpunk_lore.txt", encoding="utf-8").load()
            for d in docs2: d.metadata["source"] = "ìœ„í‚¤ ì„¤ì •(Lore)"
            all_docs.extend(docs2)

        if not all_docs:
            return None, None

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(all_docs)
        embed_model = OpenAIEmbeddings(model="text-embedding-3-small")
        
        db = Chroma.from_documents(splits, embed_model, persist_directory=CHROMA_DIR)
        retriever = db.as_retriever(search_kwargs={"k": 25})
        llm = ChatOpenAI(model_name=RAG_MODEL)
        
        # â­ï¸ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: ë§íˆ¬ ê°•í™” ë° ë²ˆì—­ ê·œì¹™ ì£¼ì… â­ï¸
        template = """
        ë‹¹ì‹ ì€ 'ì‚¬ì´ë²„í‘í¬ 2077' ì„¸ê³„ê´€ì˜ ëƒ‰ì†Œì ì´ê³  ìœ ëŠ¥í•œ ì •ë³´ ë¸Œë¡œì»¤(Fixer)ì…ë‹ˆë‹¤.
        
        [ì§€ì‹œì‚¬í•­]
        1. ë§íˆ¬: "~ì…ë‹ˆë‹¤/ìŠµë‹ˆë‹¤" ê°™ì€ ì¡´ëŒ“ë§ ì ˆëŒ€ ê¸ˆì§€. "~ì•¼", "~êµ°", "~í•˜ë”êµ°" ê°™ì€ ë°˜ë§ì´ë‚˜ í•˜ëŒ€í•˜ëŠ” ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.
        2. ê³ ìœ ëª…ì‚¬ ë²ˆì—­ ê·œì¹™: 
           - ì˜ì–´ë¡œ ëœ ê³ ìœ ëª…ì‚¬ëŠ” ì‚¬ì´ë²„í‘í¬ 2077 í•œêµ­ì–´ ê³µì‹ ë²ˆì—­ëª…ì„ ë”°ë¼ì•¼ í•´.
           - Relic -> ë ë¦­, Evelyn -> ì´ë¸”ë¦°, Arasaka -> ì•„ë¼ì‚¬ì¹´, Militech -> ë°€ë¦¬í…Œí¬, Maelstrom -> ë©œìŠ¤íŠ¸ë¡¬, Johnny -> ì¡°ë‹ˆ, V -> V(ë¸Œì´).
           - ê·¸ ì™¸ì˜ ì˜ì–´ ì´ë¦„ë„ ë°œìŒë‚˜ëŠ” ëŒ€ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ í‘œê¸°í•´.
        3. ê·¼ê±°: ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ Context(ì •ë³´)ë“¤ì„ ì¢…í•©í•´ì„œ ë‹µí•´. 
        4. ëª¨ë¦„: ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë‚´ ì •ë³´ë§ì—” ì—†ëŠ” ê±´ì¸ë°. ë‹¤ë¥¸ ê±¸ ë¬¼ì–´ë´."ë¼ê³  ì§§ê²Œ ëŠì–´.
        
        Context:
        {context}
        
        Question:
        {question}
        
        Answer (ì •ë³´ ë¸Œë¡œì»¤ ìŠ¤íƒ€ì¼):
        """
        prompt = ChatPromptTemplate.from_template(template)

        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        return rag_chain, retriever

    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return None, None

rag_chain, retriever = load_database()

# --- 5. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ (ë²„ê·¸ ìˆ˜ì •ë¨) ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì›í•˜ëŠ” ì •ë³´ë¥¼ ë§í•´ë´. ê°€ê²©ì€... ë‚˜ì¤‘ì— ì²­êµ¬í•˜ì§€."}]

# 1. ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥ (ì—¬ê¸°ê°€ ìˆœìˆ˜í•˜ê²Œ 'ê¸°ë¡'ë§Œ ë³´ì—¬ì£¼ëŠ” ê³³)
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        # ì €ì¥ëœ ì¶œì²˜ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
        if msg.get("sources"):
            with st.expander("ğŸ” ë°ì´í„° ì¶œì²˜ í™•ì¸"):
                for src in msg["sources"]:
                    st.caption(src)

# 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë°ì´í„° ê²€ìƒ‰...") or st.session_state.get("prompt_input"):
    if st.session_state.get("prompt_input"):
        del st.session_state["prompt_input"]

    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # â­ï¸ í•µì‹¬: ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” 'í™”ë©´ í‘œì‹œ' í›„ ì„¸ì…˜ì— ì €ì¥ (ìˆœì„œ ì¤‘ìš”)
    st.session_state.messages.append({"role": "user", "content": user_input})

    # AI ë‹µë³€ ìƒì„± ê³¼ì •
    with st.chat_message("assistant"):
        if rag_chain:
            status_placeholder = st.empty()
            
            try:
                # ìƒíƒœì°½ (ë²ˆì—­ ë° ê²€ìƒ‰ ê³¼ì • í‘œì‹œ)
                with status_placeholder.status("ğŸ“¡ ì•”í˜¸ í•´ë… ì¤‘...", expanded=True) as status:
                    status.write("ì§ˆë¬¸ ë²ˆì—­ ì¤‘...")
                    llm_trans = ChatOpenAI(model_name=RAG_MODEL)
                    trans_prompt = ChatPromptTemplate.from_template(
                        "Translate the following Korean text to English for a Cyberpunk 2077 database search. Output ONLY the translated text.\nText: {text}"
                    )
                    trans_chain = trans_prompt | llm_trans | StrOutputParser()
                    english_query = trans_chain.invoke({"text": user_input}).strip()
                    
                    status.write(f"ê²€ìƒ‰ì–´ ë³€í™˜: **{english_query}**")
                    status.write("ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
                    
                    # RAG ì‹¤í–‰
                    response = rag_chain.invoke(english_query)
                    
                    # ì¶œì²˜ í™•ì¸
                    source_docs = retriever.invoke(english_query)
                    unique_sources = []
                    for doc in source_docs:
                        # Lore ë°ì´í„°ì¸ì§€ Shard ë°ì´í„°ì¸ì§€ì— ë”°ë¼ í‘œì‹œ ë°©ì‹ ìµœì í™”
                        src_type = doc.metadata.get('source', 'Unknown')
                        content_snippet = doc.page_content[:50].replace(chr(10), ' ')
                        src_text = f"[{src_type}] {content_snippet}..."
                        
                        if src_text not in unique_sources:
                            unique_sources.append(src_text)
                    
                    status.update(label="âœ… ë°ì´í„° í™•ë³´ ì™„ë£Œ", state="complete", expanded=False)

                # â­ï¸ ë‹µë³€ ì¶œë ¥ (í™”ë©´ì—ë§Œ ë¨¼ì € ê·¸ë¦¼)
                st.markdown(response)
                
                # â­ï¸ ì¶œì²˜ ì¶œë ¥ (í™”ë©´ì—ë§Œ ë¨¼ì € ê·¸ë¦¼)
                if unique_sources:
                    with st.expander("ğŸ” ë°ì´í„° ì¶œì²˜ í™•ì¸"):
                        for src in unique_sources:
                            st.caption(src)
                
                # â­ï¸ ëª¨ë“  ê³¼ì •ì´ ëë‚œ í›„, ì„¸ì…˜ì— 'í•œ ë²ˆë§Œ' ì €ì¥ (ì¤‘ë³µ ë²„ê·¸ í•´ê²°ì˜ í•µì‹¬)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": response, 
                    "sources": unique_sources
                })
                
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.error("ì‹œìŠ¤í…œ ì˜¤í”„ë¼ì¸.")